{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10efb0bc7fb4feac",
   "metadata": {},
   "source": [
    "# Pilot 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3541667fd7adcabd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:55:00.014283Z",
     "start_time": "2025-09-04T16:54:59.983396Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8ce29217a91533",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309ccf480d89f99f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T17:30:20.394110Z",
     "start_time": "2025-09-04T17:30:09.559699Z"
    }
   },
   "outputs": [],
   "source": [
    "base_directory = '../data' # directory where results are\n",
    "\n",
    "output_path = base_directory + '/compiled_data.csv' # output csv of compiled data (to later merge with exported demographic data) and csv of comments\n",
    "\n",
    "prolific_df_path = base_directory + '/prolific_demographic_data.csv' # path to exported prolific demographic data\n",
    "\n",
    "def extract_first_value(df, column_name):\n",
    "    \"\"\"\n",
    "    Extracts the first non-empty value from a DataFrame column\n",
    "    \"\"\"\n",
    "    if column_name not in df.columns:\n",
    "        return np.nan\n",
    "\n",
    "    value_series = df[df[column_name].notna() & (df[column_name] != '')]\n",
    "\n",
    "    if not value_series.empty:\n",
    "        return value_series[column_name].iloc[0]\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "# data was downloaded using JATOS results archive\n",
    "all_participants_data = []\n",
    "search_pattern = os.path.join(base_directory, '**', '*.txt') # find all participant data files\n",
    "data_files = glob.glob(search_pattern, recursive=True)\n",
    "\n",
    "for file_path in data_files:\n",
    "    temp_df = pd.read_csv(file_path)\n",
    "\n",
    "    participant_vars = {\n",
    "        'success': np.nan,\n",
    "        'subject_id': np.nan,\n",
    "        'study_id': np.nan,\n",
    "        'session_id': np.nan,\n",
    "        'audio_check_passed': np.nan,\n",
    "        'audio_checks': np.nan,\n",
    "        'condition': np.nan,\n",
    "        'comprehension_failures': np.nan,\n",
    "        'collision_check': np.nan,\n",
    "        'heard_sound': np.nan,\n",
    "        'worker_comments': \"\",\n",
    "        'cork_guess': np.nan,\n",
    "        'guess': np.nan,\n",
    "        'cork_confidence': np.nan,\n",
    "        'confidence': np.nan\n",
    "    }\n",
    "\n",
    "    # extract ids\n",
    "    participant_vars['subject_id'] = extract_first_value(temp_df, 'PROLIFIC_PID')\n",
    "    participant_vars['study_id'] = extract_first_value(temp_df, 'STUDY_ID')\n",
    "    participant_vars['session_id'] = extract_first_value(temp_df, 'SESSION_ID')\n",
    "\n",
    "    # extract response to 2AFC\n",
    "    guess_rows = temp_df[temp_df['guess'].notna()]\n",
    "    if not guess_rows.empty:\n",
    "        participant_vars['cork_guess'] = guess_rows['guess'].iloc[0] # guess for cork trial\n",
    "        participant_vars['guess'] = guess_rows['guess'].iloc[1] # guess for plastic trial\n",
    "\n",
    "    # extract confidence\n",
    "    slider_rows = temp_df[temp_df['trial_type'] == 'html-slider-response']\n",
    "    if not slider_rows.empty:\n",
    "        participant_vars['cork_confidence'] = slider_rows['confidence'].iloc[0]\n",
    "        participant_vars['confidence'] = slider_rows['confidence'].iloc[1]\n",
    "\n",
    "    # check for hearing collision sound\n",
    "    sound_row = temp_df[temp_df['heard_sound'].notna() & (temp_df['heard_sound'] != '')]\n",
    "    if not sound_row.empty:\n",
    "        participant_vars['heard_sound'] = sound_row['heard_sound'].iloc[0]\n",
    "\n",
    "    # collision check and comments\n",
    "    for response_str in temp_df['response'].dropna():\n",
    "        try:\n",
    "            response_json = json.loads(response_str)\n",
    "            if 'collision_check' in response_json:\n",
    "                participant_vars['collision_check'] = response_json['collision_check']\n",
    "            if 'worker_comments' in response_json:\n",
    "                participant_vars['worker_comments'] = response_json['worker_comments']\n",
    "        except (json.JSONDecodeError, TypeError):\n",
    "            continue\n",
    "\n",
    "\n",
    "    # fallback loop for remaining single-value keys\n",
    "    for key in participant_vars.keys():\n",
    "        if pd.isna(participant_vars[key]) or participant_vars[key] == \"\":\n",
    "            participant_vars[key] = extract_first_value(temp_df, key)\n",
    "\n",
    "    all_participants_data.append(participant_vars)\n",
    "\n",
    "\n",
    "if all_participants_data:\n",
    "    final_df = pd.DataFrame(all_participants_data)\n",
    "\n",
    "    column_order = [\n",
    "        'subject_id',\n",
    "        'study_id',\n",
    "        'session_id',\n",
    "        'condition',\n",
    "        'success',\n",
    "        'audio_check_passed',\n",
    "        'audio_checks',\n",
    "        'comprehension_failures',\n",
    "        'cork_guess',\n",
    "        'cork_confidence',\n",
    "        'guess',\n",
    "        'confidence',\n",
    "        'collision_check',\n",
    "        'heard_sound',\n",
    "        'worker_comments',\n",
    "    ]\n",
    "\n",
    "    final_df = final_df[column_order]\n",
    "\n",
    "    final_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"{final_df.shape[0]} participants data written to {output_path}\")\n",
    "\n",
    "    # output csv for comments\n",
    "    comments_df = final_df[final_df['worker_comments'].notna() & (final_df['worker_comments'] != '')].copy()\n",
    "\n",
    "    if not comments_df.empty:\n",
    "        comments_output_path = output_path.replace('.csv', '_with_comments.csv')\n",
    "        comments_df.to_csv(comments_output_path, index=False)\n",
    "\n",
    "    else:\n",
    "        print(\"\\n No comments\")\n",
    "else:\n",
    "    print(\"\\nNo data was processed.\")\n",
    "\n",
    "\n",
    "##### merge dataframe with demographic data #####\n",
    "# not particularly relevant for this analysis but useful to know which participants data are missing\n",
    "\n",
    "participant_df = pd.read_csv(output_path)\n",
    "prolific_df = pd.read_csv(prolific_df_path)\n",
    "\n",
    "participant_ids = set(participant_df['subject_id'].dropna())\n",
    "prolific_ids = set(prolific_df['Participant id'].dropna())\n",
    "unmatched_ids = participant_ids.difference(prolific_ids)\n",
    "\n",
    "if unmatched_ids:\n",
    "    print(\"--- Unmatched Participant IDs (Data -> Prolific) ---\")\n",
    "    print(\"The following IDs from were NOT found in the Prolific export:\")\n",
    "    for participant_id in sorted(list(unmatched_ids)):\n",
    "        print(f\"- {participant_id}\")\n",
    "else:\n",
    "    print(\"--- ID Check (Data -> Prolific) ---\")\n",
    "    print(\"All participant IDs matched with the Prolific export.\")\n",
    "\n",
    "# filter for completed participants\n",
    "completed_prolific_df = prolific_df[prolific_df['Completed at'].notna()]\n",
    "completed_prolific_ids = set(completed_prolific_df['Participant id'].dropna())\n",
    "\n",
    "# find mismatches\n",
    "missing_from_data_ids = completed_prolific_ids.difference(participant_ids)\n",
    "\n",
    "# Print the results\n",
    "if missing_from_data_ids:\n",
    "    print(\"--- Missing Participant Data (Prolific -> Data) ---\")\n",
    "    print(\"Found in Prolific but not in Data:\")\n",
    "    for participant_id in sorted(list(missing_from_data_ids)):\n",
    "        print(f\"- {participant_id}\")\n",
    "else:\n",
    "    print(\"--- Data Completeness Check (Prolific -> Data) ---\")\n",
    "    print(\"All participant IDs matched with the Data\")\n",
    "\n",
    "\n",
    "# merge data\n",
    "merged_df = pd.merge(\n",
    "    left=participant_df,\n",
    "    right=prolific_df,\n",
    "    left_on='subject_id',\n",
    "    right_on='Participant id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# save to csv (OPTIONAL)\n",
    "output_filename = 'final_merged_data.csv'\n",
    "full_output_path = os.path.join(os.path.dirname(output_path), output_filename)\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "merged_df.to_csv(full_output_path, index=False)\n",
    "print(f\"Merged data file saved to: {full_output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d020c683506dc1be",
   "metadata": {},
   "source": [
    "### clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352309584ee0364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:55:09.392889Z",
     "start_time": "2025-09-04T16:55:09.380449Z"
    }
   },
   "outputs": [],
   "source": [
    "# full dataframe\n",
    "df = merged_df.copy()\n",
    "\n",
    "\n",
    "df_clean = df[\n",
    "    (df['audio_check_passed'] == True) & # pass audio check\n",
    "    (df['comprehension_failures'] <= 2) & # pass comprehension check\n",
    "    # remove did not hear sound in LCE and heard sound in SCE\n",
    "    ((df['condition'] != 'LCE') | (df['heard_sound'] != 'no')) &\n",
    "    ((df['condition'] != 'SCE') | (df['heard_sound'] != 'yes'))\n",
    "]\n",
    "\n",
    "df_clean['when'] = np.where(\n",
    "    (df_clean['condition'] == 'SCE') | (df_clean['condition'] == 'LCE'),\n",
    "    'early',\n",
    "    'late'\n",
    ")\n",
    "\n",
    "df_clean['sound'] = np.where(\n",
    "    (df_clean['condition'] == 'LCE') | (df_clean['condition'] == 'LCL'), # LCE and LCL are loud\n",
    "    'loud',\n",
    "    'silent'\n",
    ")\n",
    "\n",
    "print(f\"Number of participants after cleaning: {len(df_clean)}\")\n",
    "print(f\"SCE: {len(df_clean[df_clean['condition']=='SCE'])}\")\n",
    "print(f\"LCE: {len(df_clean[df_clean['condition']=='LCE'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7806487496f34fc8",
   "metadata": {},
   "source": [
    "### convert confidence to common confidence scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ae2e8497af75b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:55:09.519384Z",
     "start_time": "2025-09-04T16:55:09.501497Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "confidence_scaled calculation\n",
    "confidence: c\n",
    "\n",
    "if guess was 2 discs:\n",
    "    -c/2\n",
    "if guess was 4 discs:\n",
    "    c/2\n",
    "i.e. positive means confident there were 4 discs, negative means confident there were 2 discs\n",
    "'''\n",
    "# confidence for plastic discs\n",
    "df_clean['confidence_scaled'] = np.where(\n",
    "    df_clean['guess'] == 2.0,          # 2 discs\n",
    "    -df_clean['confidence'] / 2,       #\n",
    "    df_clean['confidence'] / 2         # Value if false\n",
    ")\n",
    "\n",
    "# confidence for cork discs\n",
    "df_clean['cork_confidence_scaled'] = np.where(\n",
    "    df_clean['cork_guess'] == 2.0,          # Condition: if 'guess' is 2\n",
    "    -df_clean['cork_confidence'] / 2,       # Value if true\n",
    "    df_clean['cork_confidence'] / 2         # Value if false\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2a552a88c66055",
   "metadata": {},
   "source": [
    "### summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f8cf1ed13cd20b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:56:33.694245Z",
     "start_time": "2025-09-04T16:56:33.623041Z"
    }
   },
   "outputs": [],
   "source": [
    "# take the difference between confidence responses\n",
    "df_clean['diff'] = df_clean['confidence_scaled'] - df_clean['cork_confidence_scaled'] # plastic - cork confidence\n",
    "# positive: more sure that there were four discs, negative: more sure that there were two discs\n",
    "\n",
    "# SCE\n",
    "plastic_sce = df_clean[df_clean['condition'] == 'SCE']['confidence_scaled']\n",
    "cork_sce = df_clean[df_clean['condition'] == 'SCE']['cork_confidence_scaled']\n",
    "diff_sce = df_clean[df_clean['condition'] == 'SCE']['diff']\n",
    "\n",
    "# LCE\n",
    "plastic_lce = df_clean[df_clean['condition'] == 'LCE']['confidence_scaled']\n",
    "cork_lce = df_clean[df_clean['condition'] == 'LCE']['cork_confidence_scaled']\n",
    "diff_lce = df_clean[df_clean['condition'] == 'LCE']['diff']\n",
    "\n",
    "print(\"Summary statistics of Scaled Confidence: \\n\")\n",
    "print(f'plastic SCE:\\n{plastic_sce.describe().round(2)}')\n",
    "print(f'\\nplastic LCE:\\n{plastic_lce.describe().round(2)}')\n",
    "print(f'\\ncork SCE:\\n{cork_sce.describe().round(2)}')\n",
    "print(f'\\ncork LCE:\\n{cork_lce.describe().round(2)}')\n",
    "\n",
    "print('\\n------------------------------------\\n')\n",
    "print('Mean and Std of Delta Confidence: \\n')\n",
    "print(f'delta conf SCE:\\n{diff_sce.describe().round(2)}')\n",
    "print(f'\\ndelta conf LCE:\\n{diff_lce.describe().round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9418dfd920909321",
   "metadata": {},
   "source": [
    "### Plots\n",
    "\n",
    "#### Figure 1: Distribution of scaled confidence by condition and material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78fd43d4f4317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:58:48.648737Z",
     "start_time": "2025-09-04T16:58:48.174258Z"
    }
   },
   "outputs": [],
   "source": [
    "# change format of df for plotting\n",
    "df_long = pd.melt(\n",
    "    df_clean,\n",
    "    id_vars=['subject_id', 'condition'],\n",
    "    value_vars=['cork_confidence_scaled', 'confidence_scaled'],\n",
    "    var_name='trial_type',\n",
    "    value_name='scaled_confidence'\n",
    ")\n",
    "\n",
    "label_map = {\n",
    "    'cork_confidence_scaled': 'cork',\n",
    "    'confidence_scaled': 'plastic'\n",
    "}\n",
    "df_long['x_category'] = df_long['condition'] + ' ' + df_long['trial_type'].map(label_map)\n",
    "\n",
    "# plotting figure\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "plot_order = [\n",
    "    'SCE cork',\n",
    "    'SCE plastic',\n",
    "    'LCE cork',\n",
    "    'LCE plastic'\n",
    "]\n",
    "\n",
    "custom_palette = {\n",
    "    'cork_confidence_scaled': 'forestgreen',\n",
    "    'confidence_scaled': 'firebrick'\n",
    "}\n",
    "\n",
    "# box plot of confidence distribution according to condition and material\n",
    "sns.boxplot(\n",
    "    data=df_long,\n",
    "    x='x_category',\n",
    "    y='scaled_confidence',\n",
    "    hue='trial_type',\n",
    "    order=plot_order,\n",
    "    palette=custom_palette,\n",
    "    fliersize=0,\n",
    "    dodge=False\n",
    ")\n",
    "\n",
    "# draw line in points within same subject to show directionality\n",
    "sns.lineplot(\n",
    "    data=df_long,\n",
    "    x='x_category',\n",
    "    y='scaled_confidence',\n",
    "    units='subject_id',\n",
    "    estimator=None,\n",
    "    color='grey',\n",
    "    alpha=0.4,\n",
    "    legend=False,\n",
    "    marker='o'\n",
    ")\n",
    "\n",
    "# for the legend\n",
    "green_patch = mpatches.Patch(color='forestgreen', label='cork')\n",
    "red_patch = mpatches.Patch(color='firebrick', label='plastic')\n",
    "\n",
    "plt.legend(handles=[green_patch, red_patch], title=\"Disc Material\")\n",
    "plt.title('Distribution of Scaled Confidence by Condition and Material', fontsize=16)\n",
    "plt.xlabel('Condition and material', fontsize=12)\n",
    "plt.ylabel('Scaled Confidence (← Sure 2  |  Sure 4 →)', fontsize=12)\n",
    "plt.ylim(-50, 50)\n",
    "plt.yticks(np.arange(-50, 51, 10))\n",
    "plt.xticks(rotation=10)\n",
    "plt.axhline(0, color='grey', linestyle='--', linewidth=1)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b343700c4c92cbd0",
   "metadata": {},
   "source": [
    "#### Figure 2: Delta confidence distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53694296be92e260",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:56:46.679843Z",
     "start_time": "2025-09-04T16:56:46.331173Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# simple violin plot of condition and delta confidence\n",
    "sns.violinplot(\n",
    "    data=df_clean,\n",
    "    x='condition',\n",
    "    y='diff',\n",
    "    inner='quart',\n",
    "    color=\".8\"\n",
    ")\n",
    "\n",
    "# jitter points\n",
    "sns.stripplot(\n",
    "    data=df_clean,\n",
    "    x='condition',\n",
    "    y='diff',\n",
    "    jitter=True,\n",
    "    color='black',\n",
    "    size=3,\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "plt.title('Delta Confidence', fontsize=16)\n",
    "plt.xlabel('Condition', fontsize=12)\n",
    "plt.ylabel('← More sure 2 plastic discs  |  More sure 4 plastic discs →', fontsize=12)\n",
    "plt.ylim(-100, 100)\n",
    "plt.yticks(np.arange(-100, 101, 10))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0380cc2e5dcc84",
   "metadata": {},
   "source": [
    "#### Distribution of collision by condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5172537b721df55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:56:51.534153Z",
     "start_time": "2025-09-04T16:56:51.350984Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "category_order = [\n",
    "    'Exactly zero',\n",
    "    'Exactly one',\n",
    "    'At least one, but possibly more',\n",
    "    'Definitely more than one'\n",
    "]\n",
    "\n",
    "\n",
    "sns.countplot(\n",
    "    data=df_clean,\n",
    "    x='collision_check',\n",
    "    hue='condition',\n",
    "    order=category_order\n",
    ")\n",
    "\n",
    "plt.title('Distribution of Collision Guesses by Condition', fontsize=16)\n",
    "plt.xlabel('Collision Guess', fontsize=12)\n",
    "plt.ylabel('Number of Participants', fontsize=12)\n",
    "plt.xticks(rotation=25, ha='right')\n",
    "plt.legend(title='Condition', loc='upper right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c553930adc2ab4",
   "metadata": {},
   "source": [
    "#### Distribution of confidence by collision guess (Plastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6212765956812ecb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:59:03.844580Z",
     "start_time": "2025-09-04T16:59:03.575283Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "category_order = [\n",
    "    'Exactly zero',\n",
    "    'Exactly one',\n",
    "    'At least one, but possibly more',\n",
    "    'Definitely more than one'\n",
    "]\n",
    "\n",
    "\n",
    "sns.boxplot(\n",
    "    data=df_clean,\n",
    "    x='collision_check',\n",
    "    y = 'confidence_scaled',\n",
    "    hue='condition',\n",
    "    order=category_order\n",
    ")\n",
    "\n",
    "\n",
    "plt.title('Distribution of Collision Guesses by Condition (Plastic)', fontsize=16)\n",
    "plt.xlabel('Collision Guess', fontsize=12)\n",
    "plt.ylabel('Scaled Confidence (← Sure 2  |  Sure 4 →)', fontsize=12)\n",
    "plt.xticks(rotation=25, ha='right')\n",
    "plt.legend(title='Condition', loc='upper right')\n",
    "plt.ylim(-50, 50)\n",
    "plt.yticks(np.arange(-50, 51, 10))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00436940d55e3ac",
   "metadata": {},
   "source": [
    "### analysis\n",
    "\n",
    "#### function for cohen's d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3328c115db6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T17:00:19.939270Z",
     "start_time": "2025-09-04T17:00:19.919918Z"
    }
   },
   "outputs": [],
   "source": [
    "def cohen_d_independent(x, y):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        x: data of one group (array-like)\n",
    "        y: data of another group (array-like)\n",
    "        (samples independent of one another)\n",
    "\n",
    "    Returns:\n",
    "        float: effect size, cohen's d for independent samples\n",
    "\n",
    "    \"\"\"\n",
    "    len_x, len_y = len(x), len(y)\n",
    "    mean_x, mean_y = np.mean(x), np.mean(y)\n",
    "    std_x, std_y = np.std(x, ddof=1), np.std(y, ddof=1)\n",
    "\n",
    "    pooled_std = np.sqrt(((len_x - 1) * std_x ** 2 + (len_y - 1) * std_y ** 2) / (len_x + len_y - 2))\n",
    "\n",
    "    if pooled_std == 0:\n",
    "        return np.inf\n",
    "\n",
    "    d = (mean_x - mean_y) / pooled_std\n",
    "    return d\n",
    "\n",
    "def cohen_d_paired(x, y):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        x: first sample (array-like)\n",
    "        y: second sample (array-like)\n",
    "\n",
    "    Returns:\n",
    "        float: effect size, cohen's d for paired samples\n",
    "    \"\"\"\n",
    "\n",
    "    differences = np.array(x) - np.array(y)\n",
    "\n",
    "    mean_diff = np.mean(differences)\n",
    "\n",
    "    std_diff = np.std(differences, ddof=1)\n",
    "\n",
    "    if std_diff == 0:\n",
    "        return np.inf\n",
    "\n",
    "    d = mean_diff / std_diff\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c1b99f3ec68a3",
   "metadata": {},
   "source": [
    "#### Hypothesis 1 - 3\n",
    "\n",
    "##### Two-way ANOVA on $C_{plastic}$ with factors sound (silent / loud) and collision time (early / late)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1dc2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols('confidence_scaled ~ C(sound) + C(when)', data=df_clean).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print('Two-way ANOVA on plastic confidence')\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90317b6d",
   "metadata": {},
   "source": [
    "##### Two-way ANOVA on $\\Delta C$ with factors sound (silent / loud) and collision time (early / late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ee5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols('diff ~ C(sound) + C(when)', data=df_clean).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print('Two-way ANOVA on plastic confidence')\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc4a0fb2a388b1e",
   "metadata": {},
   "source": [
    "##### $C_{plastic}$ SCE vs LCE, $\\Delta C$ SCE versus LCE, $C_{plastic}$ SCL vs LCL, $\\Delta C$ SCL versus LCL (depending on the results of the interaction effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396a790e7a55172d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T17:01:31.328483Z",
     "start_time": "2025-09-04T17:01:31.301728Z"
    }
   },
   "outputs": [],
   "source": [
    "# E.g.\n",
    "t_statistic, p_value = stats.ttest_ind(plastic_sce, plastic_lce, equal_var=False)\n",
    "\n",
    "print(f\"Independent samples T-test comparing confidence for plastic discs between SCE and LCE conditions.\")\n",
    "print(f\"T-statistic: {t_statistic:.5f}\")\n",
    "print(f\"P-value: {p_value:.5f}\")\n",
    "print(f\"Cohen's d: {cohen_d_independent(plastic_sce, plastic_lce):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82abd390522b5d0",
   "metadata": {},
   "source": [
    "#### Hypothesis 4\n",
    "\n",
    "##### $\\chi$-squared test for collision check responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4980f31756a6e287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T17:02:32.269580Z",
     "start_time": "2025-09-04T17:02:32.220712Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean = df_clean[df_clean['collision_check'] != 'Exactly zero']\n",
    "\n",
    "df_clean['collision_check_merged'] = df_clean['collision_check'].replace({\n",
    "    'At least one, but possibly more': 'More than one',\n",
    "    'Definitely more than one': 'More than one'\n",
    "})\n",
    "    \n",
    "contingency_table = pd.crosstab(df_clean['condition'], df_clean['collision_check_merged'])\n",
    "\n",
    "chi2_stat, p_value, dof, expected_freq = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"Chi-Squared Test Results:\")\n",
    "print(f\"Chi-Squared Statistic: {chi2_stat:.5f}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(f\"P-value: {p_value:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d691d3a4edad014",
   "metadata": {},
   "source": [
    "##### Multiple linear regression model of $C_{plastic}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c437958",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'confidence_scaled ~ C(collision_check_merged) + C(condition) + C(collision_check_merged):C(condition)'\n",
    "\n",
    "model = smf.ols(formula, data=df_clean).fit()\n",
    "\n",
    "\n",
    "print(\"Multiple Linear Regression Results\")\n",
    "print(\"=\"*35)\n",
    "print(f\"Dependent Variable: C_plastic\")\n",
    "print(f\"Independent Variables: Perceived Collisions, Condition, Interaction\")\n",
    "print(\"-\" * 35 + \"\\n\")\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psych",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
